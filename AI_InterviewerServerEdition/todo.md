# AI自主访谈机器人项目改造计划

## 现有代码结构分析

### 整体架构

现有的AI自主访谈机器人是基于Streamlit开发的单体应用，主要由前端界面、访谈逻辑处理和大模型调用三部分组成。系统通过JSON文件存储访谈大纲、问题和总结，没有使用数据库。整个应用流程是：用户输入访谈主题和关键问题，系统生成访谈框架，然后AI根据用户回答自主判断是否需要追问，最后生成访谈总结和评分。

### 核心文件功能

1. **app.py**：
   Streamlit前端应用的主入口，负责用户界面展示和交互。主要包含两个页面：访谈前准备页面（输入主题和关键问题）和查看访谈总结页面。通过session_state管理页面状态，并将用户输入的访谈大纲和关键问题保存到JSON文件中。

2. **interview_logic.py**：
   访谈逻辑的核心实现，包含多个关键功能：
   - 模型调用适配层（APIAdapter）：将原有vLLM调用转换为API调用
   - DummyTokenizer：模拟原tokenizer的模板生成逻辑
   - 访谈工具函数：包括检查问题是否可回答、生成背景问题、生成过渡语句、评估回答深度、生成深入问题、处理无法回答的情况等
   - 访谈大纲分析：对访谈大纲进行多步分析，生成评分指标
   - 生成最终总结：基于完整对话和评分指标生成JSON格式的访谈总结

3. **utils.py**：
   辅助工具函数文件，当前为空，可能是预留用于后续扩展。

4. **JSON数据文件**：
   - interview_outline.json：存储访谈大纲和关键问题
   - interview_summary.json：存储访谈总结，包含takeaways（主要结论）、points（评分）和explanations（评分解释）

5. **requirements.txt**：
   项目依赖，包含streamlit、transformers和vllm三个主要库。

### 数据流分析

1. **输入阶段**：
   用户通过Streamlit界面输入访谈大纲和关键问题，数据保存到interview_outline.json。

2. **访谈阶段**：
   - 系统读取interview_outline.json中的访谈大纲和关键问题
   - 生成背景问题和访谈框架
   - 根据用户回答评估深度，决定是否追问
   - 记录完整对话历史

3. **总结阶段**：
   - 基于对话历史和评分指标生成访谈总结
   - 将总结保存到interview_summary.json
   - 用户可在Streamlit界面查看总结

### 模型调用方式

当前系统使用了一个不规范的DummyTokenizer和APIAdapter来模拟vLLM的调用方式，实际上是通过HTTP请求调用远程API。主要问题包括：

1. 使用了硬编码的API地址和模型路径
2. 模拟的tokenizer功能不完整
3. 缺乏错误处理和重试机制
4. 没有考虑并发请求的情况

## 待改造内容

- [x] 分析现有代码结构和功能
- [x] 设计模块化架构（前端Vue、后端JavaScript、模型服务）
- [x] 重构代码，实现前后端分离
- [x] 集成MongoDB数据库，实现访谈主题列表功能
- [x] 增强后端以支持并发和标准vLLM架构
- [x] 添加多模态分析接口（面部表情和声音分析）
- [x] 验证功能和代码质量
- [x] 完成最终代码和文档
